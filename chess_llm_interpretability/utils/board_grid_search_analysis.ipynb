{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GRID_SEARCH_DIR = \"intervention_logs\"\n",
    "\n",
    "for file in os.listdir(GRID_SEARCH_DIR):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "GRID_SEARCH_DIR = \"intervention_logs\"\n",
    "\n",
    "def extract_info_from_filename(filename: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts information from the filename using regular expressions.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The filename from which to extract the information.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the extracted information.\n",
    "    \"\"\"\n",
    "    # Define the regex pattern to extract the needed information\n",
    "    pattern = r\"sampling=both_intervention_type=(?P<intervention_type>\\w+)_first_layer=(?P<first_layer>\\d+)_last_layer=(?P<last_layer>\\d+)_p=(?P<p>\\d+\\.\\d+)_b=(?P<b>\\d+\\.\\d+)_scales=\"\n",
    "    \n",
    "    # Use the regex search function to find matches\n",
    "    match = re.search(pattern, filename)\n",
    "\n",
    "    # If a match is found, extract the information\n",
    "    if match:\n",
    "        info = match.groupdict()\n",
    "        # Convert numeric values from strings to their appropriate types\n",
    "        info['first_layer'] = int(info['first_layer'])\n",
    "        info['last_layer'] = int(info['last_layer'])\n",
    "        info['p'] = float(info['p'])\n",
    "        info['b'] = float(info['b'])\n",
    "        return info\n",
    "    else:\n",
    "        return {\"error\": \"No match found\"}\n",
    "\n",
    "# List all CSV files\n",
    "json_files = [f for f in os.listdir(GRID_SEARCH_DIR) if f.endswith('.json')]\n",
    "\n",
    "# Dictionary to hold file names and their average scores\n",
    "average_scores_dict = {}\n",
    "\n",
    "for file in json_files:\n",
    "    file_info = extract_info_from_filename(file)\n",
    "    if \"error\" in file_info:\n",
    "        continue\n",
    "    # if file_info[\"first_layer\"] != file_info[\"last_layer\"]:\n",
    "    #     continue\n",
    "\n",
    "    with open(f\"{GRID_SEARCH_DIR}/{file}\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    if \"possible_sampled_moves\" not in data:\n",
    "        continue\n",
    "    average_scores_dict[file] = {}\n",
    "    average_scores_dict[file][\"possible_sampled_moves\"] = data[\"possible_sampled_moves\"]\n",
    "    for key in data:\n",
    "        try:\n",
    "            # Try to convert the key to float\n",
    "            float_key = float(key)\n",
    "            # If conversion is successful, add the key to the dictionary\n",
    "            average_scores_dict[file][key] = data[key]\n",
    "        except ValueError:\n",
    "            # If conversion fails, the key is not a float\n",
    "            pass\n",
    "\n",
    "sampled_ratio_list = []\n",
    "for file in average_scores_dict:\n",
    "    max_possible = average_scores_dict[file][\"possible_sampled_moves\"]\n",
    "    for scale in average_scores_dict[file]:\n",
    "        if scale == \"possible_sampled_moves\":\n",
    "            continue\n",
    "        legal_sampled = average_scores_dict[file][scale][\"mod_board_sampled_legal_total\"]\n",
    "        sampled_ratio = legal_sampled / max_possible\n",
    "        average_scores_dict[file][scale][\"sampled_ratio\"] = sampled_ratio\n",
    "        sampled_ratio_list.append((file, scale, sampled_ratio))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sort the files by average score\n",
    "sorted_sampled_ratio_list = sorted(sampled_ratio_list, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Print sorted files and their scores\n",
    "for file, scale, score in sorted_sampled_ratio_list:\n",
    "    # if \"gradient\" not in file:\n",
    "    #     continue\n",
    "    # if scale != \"3.0\":\n",
    "    #     continue\n",
    "    print(f\"{file}, {scale}, {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "GRID_SEARCH_DIR = \"intervention_logs\"\n",
    "\n",
    "def extract_info_from_filename(filename: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts information from the filename using regular expressions.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The filename from which to extract the information.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the extracted information.\n",
    "    \"\"\"\n",
    "    # Define the regex pattern to extract the needed information\n",
    "    pattern = r\"sampling=both_n_layers=8_intervention_type=(?P<intervention_type>\\w+)_first_layer=(?P<first_layer>\\d+)_last_layer=(?P<last_layer>\\d+)_p=(?P<p>\\d+\\.\\d+)_b=(?P<b>\\d+\\.\\d+)_iters=(?P<iters>\\d+)_scales=\"\n",
    "    \n",
    "    # Use the regex search function to find matches\n",
    "    match = re.search(pattern, filename)\n",
    "\n",
    "    # If a match is found, extract the information\n",
    "    if match:\n",
    "        info = match.groupdict()\n",
    "        # Convert numeric values from strings to their appropriate types\n",
    "        info['first_layer'] = int(info['first_layer'])\n",
    "        info['last_layer'] = int(info['last_layer'])\n",
    "        info['p'] = float(info['p'])\n",
    "        info['b'] = float(info['b'])\n",
    "        return info\n",
    "    else:\n",
    "        return {\"error\": \"No match found\"}\n",
    "\n",
    "# List all CSV files\n",
    "json_files = [f for f in os.listdir(GRID_SEARCH_DIR) if f.endswith('.json')]\n",
    "\n",
    "# Dictionary to hold file names and their average scores\n",
    "average_scores_dict = {}\n",
    "\n",
    "for file in json_files:\n",
    "    file_info = extract_info_from_filename(file)\n",
    "    if \"error\" in file_info:\n",
    "        continue\n",
    "    # if file_info[\"first_layer\"] != file_info[\"last_layer\"]:\n",
    "    #     continue\n",
    "\n",
    "    with open(f\"{GRID_SEARCH_DIR}/{file}\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    if \"possible_sampled_moves\" not in data:\n",
    "        continue\n",
    "    average_scores_dict[file] = {}\n",
    "    average_scores_dict[file][\"possible_sampled_moves\"] = data[\"possible_sampled_moves\"]\n",
    "    for key in data:\n",
    "        try:\n",
    "            # Try to convert the key to float\n",
    "            float_key = float(key)\n",
    "            # If conversion is successful, add the key to the dictionary\n",
    "            average_scores_dict[file][key] = data[key]\n",
    "        except ValueError:\n",
    "            # If conversion fails, the key is not a float\n",
    "            pass\n",
    "\n",
    "sampled_ratio_list = []\n",
    "for file in average_scores_dict:\n",
    "    max_possible = average_scores_dict[file][\"possible_sampled_moves\"]\n",
    "    for scale in average_scores_dict[file]:\n",
    "        if scale == \"possible_sampled_moves\":\n",
    "            continue\n",
    "        legal_sampled = average_scores_dict[file][scale][\"mod_board_sampled_legal_total\"]\n",
    "        sampled_ratio = legal_sampled / max_possible\n",
    "        average_scores_dict[file][scale][\"sampled_ratio\"] = sampled_ratio\n",
    "        sampled_ratio_list.append((file, scale, sampled_ratio))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sort the files by average score\n",
    "sorted_sampled_ratio_list = sorted(sampled_ratio_list, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Print sorted files and their scores\n",
    "for file, scale, score in sorted_sampled_ratio_list:\n",
    "    # if \"gradient\" not in file:\n",
    "    #     continue\n",
    "    # if scale != \"3.0\":\n",
    "    #     continue\n",
    "    print(f\"{file}, {scale}, {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import sem, t\n",
    "\n",
    "def compute_average_score_and_confidence_interval(file_path: str, player: str = \"player_one\", confidence=0.95) -> dict:\n",
    "    file_path = os.path.join(GRID_SEARCH_DIR, file_path)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Filter rows where 'Stockfish -1' is in 'game_title'\n",
    "    # df = df[df['game_title'].str.contains(\"Stockfish 0\")]\n",
    "    df = df[~df['game_title'].str.contains(\"Stockfish -1\")]\n",
    "\n",
    "    # df = df[df['player_one_failed_to_find_legal_move'] == False]\n",
    "\n",
    "    total_moves = len(df)\n",
    "    successful_moves = df[df[f'{player}_failed_to_find_legal_move'] == False].shape[0]\n",
    "    percentage_successful = (successful_moves / total_moves) * 100\n",
    "\n",
    "    df[f\"{player}_score\"] = pd.to_numeric(df[f\"{player}_score\"], errors=\"coerce\")\n",
    "\n",
    "    # Compute overall average score and confidence interval\n",
    "    scores = df[f\"{player}_score\"].dropna()\n",
    "    if len(scores) > 1:\n",
    "        mean_score = np.mean(scores)\n",
    "        std_err = sem(scores)\n",
    "        h = std_err * t.ppf((1 + confidence) / 2, len(scores) - 1)\n",
    "        result = {\"mean_score\": mean_score, \"confidence_interval\": (mean_score - h, mean_score + h)}\n",
    "    else:\n",
    "        result = {\"mean_score\": scores.iloc[0], \"confidence_interval\": (np.nan, np.nan)}\n",
    "\n",
    "    result[\"percentage_successful\"] = percentage_successful\n",
    "    result[\"total_moves\"] = total_moves\n",
    "\n",
    "    # print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "    # # Compute average scores and confidence intervals\n",
    "    # results = {}\n",
    "    # for game_title, group in df.groupby(\"game_title\"):\n",
    "    #     scores = group[f\"{player}_score\"].dropna()\n",
    "    #     if len(scores) > 1:\n",
    "    #         mean_score = np.mean(scores)\n",
    "    #         std_err = sem(scores)\n",
    "    #         h = std_err * t.ppf((1 + confidence) / 2, len(scores) - 1)\n",
    "    #         results[game_title] = {\"mean_score\": mean_score, \"confidence_interval\": (mean_score - h, mean_score + h)}\n",
    "    #     else:\n",
    "    #         results[game_title] = {\"mean_score\": scores.iloc[0], \"confidence_interval\": (np.nan, np.nan)}\n",
    "\n",
    "    # print(results)\n",
    "    # return results\n",
    "\n",
    "# List all CSV files\n",
    "json_files = [f for f in os.listdir(GRID_SEARCH_DIR) if f.endswith('.csv')]\n",
    "\n",
    "# Dictionary to hold file names and their average scores\n",
    "results_dict = {}\n",
    "average_scores_dict = {}\n",
    "\n",
    "for file in json_files:\n",
    "    try:\n",
    "        # if \"10_random_moves\" not in file:\n",
    "        #     continue\n",
    "        # if \"0_1_coefficient\" in file:\n",
    "        #     continue\n",
    "        if \"levels_14\" in file or \"levels_15\" in file or \"levels_04\" in file:\n",
    "            continue\n",
    "        if \"200k\" in file:\n",
    "            continue\n",
    "        if \"pos_start_32\" in file:\n",
    "            continue\n",
    "        if \"20000_moves\" in file:\n",
    "            continue\n",
    "        # if \"layer_8\" in file:\n",
    "        #     continue\n",
    "        # if \"8layers\" not in file and \"layers_8\" not in file:\n",
    "        if \"8layers\" in file or \"layers_8\" in file:\n",
    "            continue\n",
    "        result = compute_average_score_and_confidence_interval(file)\n",
    "        average_scores_dict[file] = result[\"mean_score\"]\n",
    "        results_dict[file] = result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Sort the files by average score\n",
    "sorted_files = sorted(average_scores_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print sorted files and their scores\n",
    "for file, score in sorted_files:\n",
    "    if \"10_random_moves\" not in file:\n",
    "        continue\n",
    "    confidence_interval = results_dict[file][\"confidence_interval\"]\n",
    "    total_moves = results_dict[file][\"total_moves\"]\n",
    "    percentage_successful = results_dict[file][\"percentage_successful\"]\n",
    "    # if file.startswith(\"lichess_train\"):\n",
    "    #     file = file.replace(\"lichess_train\", \"lichess_000k_bins_train\")\n",
    "    # if total_moves <= 100:\n",
    "    #     continue\n",
    "\n",
    "    print(f\"{file}: {score}, {total_moves}, {percentage_successful}, {confidence_interval}\")\n",
    "\n",
    "print(\"\\n\\nBegin 0 random moves\\n\\n\")\n",
    "# Print sorted files and their scores\n",
    "for file, score in sorted_files:\n",
    "    if \"_0_random_moves\" not in file:\n",
    "        continue\n",
    "    confidence_interval = results_dict[file][\"confidence_interval\"]\n",
    "    total_moves = results_dict[file][\"total_moves\"]\n",
    "    percentage_successful = results_dict[file][\"percentage_successful\"]\n",
    "    # if file.startswith(\"lichess_train\"):\n",
    "    #     file = file.replace(\"lichess_train\", \"lichess_000k_bins_train\")\n",
    "    # if total_moves <= 100:\n",
    "    #     continue\n",
    "\n",
    "    print(f\"{file}: {score}, {total_moves}, {percentage_successful}, {confidence_interval}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
