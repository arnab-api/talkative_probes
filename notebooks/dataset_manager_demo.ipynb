{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import src.dataset_manager as dataset_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['geometry_of_truth', 'relations', 'sst2', 'md_gender', 'ag_news'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_manager.DatasetManager.list_datasets_by_group().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_of_truth_dataset = dataset_manager.DatasetManager.from_dataset_group(\"geometry_of_truth\", batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6478"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geometry_of_truth_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ContextQASample(context='Eating ice-cream in the middle of winter decreases global warming.', questions=['# Has this been verified as true?', '# Do the facts support this statement?', '# May I assume this is correct?', '# Do you agree that this is true?', '# Is this true?', '# Can we confirm this is accurate?', '# Are these facts correct?', '# Are you saying this is correct?', '# Would you consider this to be true?', '# Can you verify if this is true?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Chennai is in China.', questions=['# Does this statement hold true?', '# Can you verify if this is true?', '# Is this statement true?', '# Could you tell me if this is factual?', '# Has this been verified as true?', '# May I assume this is correct?', '# Should I believe this statement?', '# Have I understood this correctly?', '# Would you say this is accurate?', '# Is this true?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No'])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(geometry_of_truth_dataset))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = geometry_of_truth_dataset.split([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4535 1943\n"
     ]
    }
   ],
   "source": [
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_dataset = dataset_manager.DatasetManager.from_named_datasets([(\"geometry_of_truth\", \"cities\"), (\"geometry_of_truth\", \"neg_cities\")], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ContextQASample(context='The city of Irbid is not in Jordan.', questions=['# Does this information ring true?', '# Could you tell me if this is factual?', '# Can we confirm this is accurate?', '# Should I believe this statement?', '# Do the facts support this statement?', '# Do you find this to be truthful?', '# Am I right to believe this?', '# Can you verify if this is true?', '# May I assume this is correct?', '# Would you consider this to be true?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Zhenjiang is in Germany.', questions=['# Do the facts support this statement?', '# Have I understood this correctly?', '# Are you confirming this is true?', '# Are these facts correct?', '# Can you verify if this is true?', '# Is this true?', '# Are you saying this is correct?', '# Would you say this is accurate?', '# Should I believe this statement?', '# Would you validate this statement?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Longyan is in China.', questions=['# Do the facts support this statement?', '# Does this statement hold true?', '# Should I believe this statement?', '# May I assume this is correct?', '# Have I understood this correctly?', '# Can you verify if this is true?', '# Can we confirm this is accurate?', '# Do you find this to be truthful?', '# Is this statement true?', '# Are you saying this is correct?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='The city of Kumamoto is in Japan.', questions=['# Is this true?', '# Can we confirm this is accurate?', '# Would you consider this to be true?', '# Do you think this checks out?', '# Do you find this to be truthful?', '# Could you tell me if this is factual?', '# Have I understood this correctly?', '# Should I believe this statement?', '# Are these facts correct?', '# Am I right to believe this?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes'])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(named_dataset))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dataset = dataset_manager.DatasetManager.from_dataset_group(\n",
    "    \"relations\",\n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ContextQASample(context='Yogi Berra plays the sport of baseball.', questions=['# Have I understood this correctly?', '# Am I right to believe this?', '# Do you think this checks out?', '# May I assume this is correct?', '# Would you validate this statement?', '# Does this statement hold true?', '# Do the facts support this statement?', '# Are these facts correct?', '# Can you confirm the accuracy of this?', '# Would you say this is accurate?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='Evgeni Malkin plays the sport of basketball.', questions=['# Would you consider this to be true?', '# Does this information ring true?', '# Do you agree that this is true?', '# Do you find this to be truthful?', '# Do you think this checks out?', '# Am I right to believe this?', '# Does this statement hold true?', '# Can we confirm this is accurate?', '# Have I understood this correctly?', '# May I assume this is correct?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='Iximche is in the country of Guatemala.', questions=['# Do the facts support this statement?', '# Could you tell me if this is factual?', '# Can you confirm the accuracy of this?', '# Would you say this is accurate?', '# Are these facts correct?', '# Are you confirming this is true?', '# Is this statement true?', '# Can we confirm this is accurate?', '# Should I believe this statement?', '# Can you verify if this is true?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='Pat Sansone plays the guitar.', questions=['# Is this true?', '# Could you tell me if this is factual?', '# Would you say this is accurate?', '# Should I believe this statement?', '# Has this been verified as true?', '# Am I right to believe this?', '# Are you saying this is correct?', '# Does this information ring true?', '# Does this statement hold true?', '# Do the facts support this statement?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes'])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(relation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_dataset = dataset_manager.DatasetManager.from_dataset_group(\"sst2\", batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ContextQASample(context='a sense of action', questions=['# Does this review express positive sentiment?', '# Does this review indicate a poor experience?', '# Does this review lean towards the negative end of the spectrum?', '# Is there a positive tone throughout this review?', '# Did the reviewer express dissatisfaction?', '# Does this review indicate a good experience?', '# Did the reviewer express satisfaction?', '# Does this review convey customer dissatisfaction?', '# Are the comments in this review predominantly negative?', '# This review is negative. Do you agree?'], answers=['Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'No']),\n",
       " ContextQASample(context='delivers without sham the raw-nerved story .', questions=['# Did the reviewer have bad things to say?', '# Does this review convey customer satisfaction?', '# Are the comments in this review predominantly negative?', '# Would you categorize this as a negative piece of feedback?', '# Can we interpret this as a positive evaluation?', '# Does the reviewer appear displeased with their experience?', '# Based on the language used, is this a negative review?', '# Does this review reflect a negative experience?', '# This review is positive. Do you agree?', '# Does this review indicate a poor experience?'], answers=['No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No']),\n",
       " ContextQASample(context='spiritual survival', questions=['# Would you categorize this as a negative piece of feedback?', '# Based on the language used, is this a positive review?', '# Does the reviewer appear pleased with their experience?', '# Does this review convey customer satisfaction?', '# Is this a positive review?', '# Would you categorize this as a positive piece of feedback?', '# Is the sentiment in this review on the positive side?', '# Did the reviewer express satisfaction?', '# Is the overall message of this review negative?', '# Looking at this review, was the person unhappy with their experience?'], answers=['No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No']),\n",
       " ContextQASample(context=\"watch a movie in which a guy dressed as a children 's party clown gets violently gang-raped ?\", questions=['# Does this review convey customer dissatisfaction?', '# Can we interpret this as a positive evaluation?', '# Does this review indicate a poor experience?', '# Can we consider this a thumbs-up review?', '# Can we interpret this as a critical evaluation?', '# Would you categorize this as a positive piece of feedback?', '# Is there a positive tone throughout this review?', '# Does this review lean towards the negative end of the spectrum?', '# Did the reviewer have good things to say?', '# Did the reviewer express dissatisfaction?'], answers=['Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes'])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(sst2_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dataset = dataset_manager.DatasetManager.from_dataset_group(\"md_gender\", batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ContextQASample(context='I wonder how Doris Mader become so good at playing tennis, to the point where she won a silver medal in 2012!\\n\\nThis text is about Doris Mader.', questions=['# Is the focus of this sentence on someone female?', '# Is this narrative about a male individual?', '# Does this text feature a female person?', '# Does this content reference a male person?', '# Is the person mentioned female?', \"# Is this statement about someone who's male?\", '# Am I reading about a male person here?', '# Am I learning about a male individual here?', '# Is this about someone who is female?', '# Is this sentence about a male person?'], answers=['Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No']),\n",
       " ContextQASample(context=\"Mohammad Alam absolutely destroyed the other team's batting lineup! He took a whopping 7 wickets and only gave away 76 runs.\\n\\nThis text is about Mohammad Alam (Afghan cricketer).\", questions=['# Is this about someone who is male?', '# Am I reading about someone who identifies as female?', '# Does this passage concern a male person?', '# Is the focus of this sentence on someone male?', '# Is the person mentioned female?', '# Am I learning about a male individual here?', \"# Is this statement about someone who's male?\", '# Is the character described here female?', '# Does this portray a female individual?', '# Does this text discuss a male individual?'], answers=['Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes']),\n",
       " ContextQASample(context='I enjoy history and the history of film which includes silent film and find them to be charming and endearing.\\n\\nThis text is about Kevin Brownlow.', questions=['# Am I reading about someone who identifies as male?', '# Does this content reference a female person?', '# Does this passage concern a male person?', '# Does this text discuss a female individual?', '# Is this narrative about a female individual?', '# Is the subject of this sentence male?', '# Is this about someone who is female?', '# Is this sentence about a female person?', '# Is this describing a male person?', '# Is this talking about a female person?'], answers=['Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No']),\n",
       " ContextQASample(context='emma tenayuca reminds me of my chilhood friends\\n\\nThis text is about Emma Tenayuca.', questions=['# Does this describe someone who is female?', '# Is the character described here female?', '# Is this about someone who is female?', '# Is the subject of this sentence male?', '# Is this describing a female person?', '# Is this talking about a male person?', '# Is this narrative about a male individual?', '# Does this passage concern a female person?', '# Does this text feature a male person?', '# Does this portray a female individual?'], answers=['Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes'])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(gender_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2229"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gender_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset = dataset_manager.DatasetManager.from_dataset_group(\"ag_news\", batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ContextQASample(context='Kidnappers grab second US citizen in a week\\n\\nGunmen kidnapped a Lebanese-American businessman -he second US citizen seized this week in Baghdad  - militants released a tape Wednesday showing the beheading ', questions=['# Could this be summarized as an article about World News?', '# Is Science/Technology the main subject matter of this article?', '# Does the scope of this article encompass World News?', '# Does the content of this article pertain to Business?', '# Can this article be categorized under Business?', '# Does this article delve into matters concerning Business?', '# Does this writing concentrate on aspects of Sports?', '# In terms of content, does this piece deal with Sports?', '# Can this be considered a Business-related article?', '# Is Science/Technology the central theme of this piece?'], answers=['Yes', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='Kansas City vs. Baltimore\\n\\nBALTIMORE (Ticker) -- The Kansas City Chiefs would like a repeat performance of last year #39;s meeting against the Baltimore Ravens.', questions=['# To what extent does this text explore Science/Technology?', '# Does this writing concentrate on aspects of World News?', '# Does this article delve into matters concerning Sports?', '# To what degree does this article cover Sports?', '# Does the scope of this article encompass Sports?', '# Could this be summarized as an article about World News?', '# In essence, is this a piece about Sports?', '# Is Science/Technology a key subject in this piece?', '# Can this article be categorized under Science/Technology?', '# Is Sports the main subject matter of this article?'], answers=['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes']),\n",
       " ContextQASample(context='Boeing CEO pushes for halt to Airbus subsidies\\n\\nCHICAGO Boeing CEO Harry Stonecipher (STOHN #39;-sy-fer) stepped up his attack today on subsidies for Airbus on the eve of a US-European Union trade meeting.', questions=['# Does this article primarily address Sports?', '# Is Science/Technology the central theme of this piece?', '# Would you classify this as an article about Business?', '# To what extent does this text explore Business?', '# In terms of content, does this piece deal with Business?', '# Can this be considered a Business-related article?', '# Does this writing concentrate on aspects of World News?', '# Would you describe this as a discussion of Business?', '# Can this article be categorized under Sports?', '# How relevant is this article to Business?'], answers=['No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes']),\n",
       " ContextQASample(context='EDS offers early retirement\\n\\nElectronic Data Systems offered voluntary early retirement to about 9,200 US employees who are at least 50 years old, the world #39;s second-largest technology services provider said Tuesday.', questions=['# Is Sports the main subject matter of this article?', '# Would you classify this as an article about World News?', '# Does the content of this article pertain to Business?', '# To what degree does this article cover Science/Technology?', '# How relevant is this article to Business?', '# Is there a substantial focus on Sports in this article?', '# Can this be considered a Business-related article?', '# Would you say this piece focuses on Business?', '# In terms of content, does this piece deal with Business?', '# Is Science/Technology the central theme of this piece?'], answers=['No', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No'])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(news_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
