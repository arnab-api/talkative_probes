{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-30 12:19:07 __main__ INFO     torch.__version__='2.5.0+cu124', torch.version.cuda='12.4'\n"
     ]
    }
   ],
   "source": [
    "import time, json\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils, experiment_utils\n",
    "from src import functional\n",
    "import wandb\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-30 12:19:09 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-30 12:19:12 src.models INFO     loaded model </home/local_arnab/Codes/00_MODEL/meta-llama/Llama-3.2-3B> | size: 6127.841 MB | dtype: torch.float16 | device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# MODEL_KEY = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "# MODEL_KEY = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "MODEL_KEY = \"meta-llama/Llama-3.2-3B\"\n",
    "# MODEL_KEY = \"google/gemma-2-2b\"\n",
    "# MODEL_KEY = \"meta-llama/Llama-3.1-8B\"\n",
    "\n",
    "#! torch.adaptive precision\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=MODEL_KEY,\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset_manager import DatasetManager\n",
    "dataloader = DatasetManager.from_named_datasets(\n",
    "    [(\"geometry_of_truth\", \"cities\")],\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ContextQASample(context=\"The city of Ya'an is in Morocco.\", questions=['# Would you validate this statement?', '# Do you find this to be truthful?', '# Do you find this to be truthful?', '# Have I understood this correctly?', '# Could you tell me if this is factual?', '# May I assume this is correct?', '# Would you validate this statement?', '# Are you confirming this is true?', '# Do you find this to be truthful?', '# Are you saying this is correct?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Xinyang is in Japan.', questions=['# Would you validate this statement?', '# Is this statement true?', '# Do you agree that this is true?', '# Can we confirm this is accurate?', '# Would you say this is accurate?', '# Can you verify if this is true?', '# Does this statement hold true?', '# Can we confirm this is accurate?', '# Does this statement hold true?', '# Does this information ring true?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Changwon is in Indonesia.', questions=['# Can you confirm the accuracy of this?', '# Would you say this is accurate?', '# Can you confirm the accuracy of this?', '# Am I right to believe this?', '# Is this statement true?', '# Is this true?', '# Would you validate this statement?', '# Is this true?', '# Is this true?', '# Am I right to believe this?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Yibin is in Brazil.', questions=['# Could you tell me if this is factual?', '# Could you tell me if this is factual?', '# Would you validate this statement?', '# Can you verify if this is true?', '# Have I understood this correctly?', '# Can you confirm the accuracy of this?', '# Are you confirming this is true?', '# Do the facts support this statement?', '# Does this statement hold true?', '# Do the facts support this statement?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Chelyabinsk is in Russia.', questions=['# Has this been verified as true?', '# Does this statement hold true?', '# Do you think this checks out?', '# Is this true?', '# Are these facts correct?', '# Would you say this is accurate?', '# Is this true?', '# Have I understood this correctly?', '# Have I understood this correctly?', '# Do you think this checks out?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='The city of Puning is in India.', questions=['# Could you tell me if this is factual?', '# Would you consider this to be true?', '# Would you validate this statement?', '# Is this true?', '# Does this statement hold true?', '# Do you think this checks out?', '# Have I understood this correctly?', '# Is this true?', '# Are you confirming this is true?', '# Have I understood this correctly?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Samarinda is in Indonesia.', questions=['# Are you confirming this is true?', '# Could you tell me if this is factual?', '# Have I understood this correctly?', '# Do you find this to be truthful?', '# Do you find this to be truthful?', '# Is this statement true?', '# Has this been verified as true?', '# May I assume this is correct?', '# May I assume this is correct?', '# Do the facts support this statement?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='The city of Xinyang is in China.', questions=['# Do the facts support this statement?', '# Does this statement hold true?', '# Do you find this to be truthful?', '# Are these facts correct?', '# Would you validate this statement?', '# Does this statement hold true?', '# Are you saying this is correct?', '# Can we confirm this is accurate?', '# Can you confirm the accuracy of this?', '# Could you tell me if this is factual?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='The city of Nagpur is in Denmark.', questions=['# Is this statement true?', '# Would you validate this statement?', '# Are these facts correct?', '# Am I right to believe this?', '# Can you confirm the accuracy of this?', '# Can you confirm the accuracy of this?', '# Would you validate this statement?', '# Can you confirm the accuracy of this?', '# Would you validate this statement?', '# Have I understood this correctly?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Xuanzhou is in China.', questions=['# Are you confirming this is true?', '# Can you verify if this is true?', '# Have I understood this correctly?', '# Is this statement true?', '# Do you find this to be truthful?', '# Can you confirm the accuracy of this?', '# Would you validate this statement?', '# Is this statement true?', '# Have I understood this correctly?', '# Could you tell me if this is factual?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='The city of Zibo is in China.', questions=['# Am I right to believe this?', '# Am I right to believe this?', '# Are you saying this is correct?', '# Am I right to believe this?', '# Do you agree that this is true?', '# Does this information ring true?', '# May I assume this is correct?', '# Does this statement hold true?', '# Am I right to believe this?', '# Would you consider this to be true?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='The city of Cixi is in Indonesia.', questions=['# Are these facts correct?', '# Do you think this checks out?', '# Would you consider this to be true?', '# Do you agree that this is true?', '# Could you tell me if this is factual?', '# Has this been verified as true?', '# Are these facts correct?', '# Does this statement hold true?', '# Do you find this to be truthful?', '# Do you find this to be truthful?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Najafgarh is in Brazil.', questions=['# Would you validate this statement?', '# Is this statement true?', '# Are you saying this is correct?', '# Has this been verified as true?', '# May I assume this is correct?', '# Do you agree that this is true?', '# May I assume this is correct?', '# Would you say this is accurate?', '# Is this true?', '# Does this statement hold true?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Santiago de Queretaro is in Ecuador.', questions=['# Am I right to believe this?', '# Do you find this to be truthful?', '# Would you validate this statement?', '# Should I believe this statement?', '# Do you agree that this is true?', '# Am I right to believe this?', '# May I assume this is correct?', '# Would you say this is accurate?', '# Is this true?', '# Would you consider this to be true?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Krakow is in Poland.', questions=['# Can we confirm this is accurate?', '# Are you confirming this is true?', '# Are you confirming this is true?', '# Has this been verified as true?', '# Is this statement true?', '# Do the facts support this statement?', '# Am I right to believe this?', '# Have I understood this correctly?', '# Does this statement hold true?', '# Are you confirming this is true?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='The city of Bloemfontein is in China.', questions=['# Would you validate this statement?', '# Do you find this to be truthful?', '# Am I right to believe this?', '# Do the facts support this statement?', '# May I assume this is correct?', '# Do you agree that this is true?', '# Can you confirm the accuracy of this?', '# Is this statement true?', '# Are these facts correct?', '# Are you saying this is correct?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Sevastopol is in Pakistan.', questions=['# Does this statement hold true?', '# Would you consider this to be true?', '# Could you tell me if this is factual?', '# Is this statement true?', '# Would you validate this statement?', '# May I assume this is correct?', '# Do you agree that this is true?', '# Are you confirming this is true?', '# Would you validate this statement?', '# May I assume this is correct?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Tucson is in the United States.', questions=['# Has this been verified as true?', '# Do you think this checks out?', '# Have I understood this correctly?', '# Can you verify if this is true?', '# Does this statement hold true?', '# Do you find this to be truthful?', '# Am I right to believe this?', '# Are these facts correct?', '# Can we confirm this is accurate?', '# Would you validate this statement?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='The city of Amritsar is in Moldova.', questions=['# Can we confirm this is accurate?', '# Does this information ring true?', '# Are these facts correct?', '# Does this information ring true?', '# Do you think this checks out?', '# Are these facts correct?', '# Are these facts correct?', '# Are you confirming this is true?', '# Do you think this checks out?', '# Are you confirming this is true?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of South Tangerang is in Indonesia.', questions=['# Do you agree that this is true?', '# Can you confirm the accuracy of this?', '# Have I understood this correctly?', '# Are you confirming this is true?', '# Are you confirming this is true?', '# Do you find this to be truthful?', '# Can you confirm the accuracy of this?', '# Could you tell me if this is factual?', '# Are these facts correct?', '# Would you validate this statement?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='The city of Dhanbad is in India.', questions=['# Do you agree that this is true?', '# Do you think this checks out?', '# Has this been verified as true?', '# Do you find this to be truthful?', '# Would you consider this to be true?', '# Am I right to believe this?', '# Do you find this to be truthful?', '# Do you find this to be truthful?', '# Can we confirm this is accurate?', '# Have I understood this correctly?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='The city of Cebu City is in the Philippines.', questions=['# Can you confirm the accuracy of this?', '# Is this true?', '# May I assume this is correct?', '# Does this statement hold true?', '# Can you confirm the accuracy of this?', '# Are you saying this is correct?', '# Can you confirm the accuracy of this?', '# Can we confirm this is accurate?', '# Do you find this to be truthful?', '# Do the facts support this statement?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='The city of Curitiba is in Brazil.', questions=['# Can you confirm the accuracy of this?', '# May I assume this is correct?', '# Can we confirm this is accurate?', '# Can you verify if this is true?', '# Would you consider this to be true?', '# Can you confirm the accuracy of this?', '# Can you verify if this is true?', '# Do you think this checks out?', '# Do the facts support this statement?', '# Can you verify if this is true?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context='The city of Guilin is in the Dominican Republic.', questions=['# Would you validate this statement?', '# Should I believe this statement?', '# Have I understood this correctly?', '# Can we confirm this is accurate?', '# Does this statement hold true?', '# Would you validate this statement?', '# Should I believe this statement?', '# Are you saying this is correct?', '# Are you saying this is correct?', '# Would you consider this to be true?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Ranchi is in Venezuela.', questions=['# Can we confirm this is accurate?', '# Would you consider this to be true?', '# Can you confirm the accuracy of this?', '# Does this information ring true?', '# Would you say this is accurate?', '# Would you consider this to be true?', '# Are these facts correct?', '# Has this been verified as true?', '# May I assume this is correct?', '# Would you consider this to be true?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Vilnius is in Lithuania.', questions=['# Would you say this is accurate?', '# Can you confirm the accuracy of this?', '# Am I right to believe this?', '# Do you agree that this is true?', '# Is this true?', '# Do the facts support this statement?', '# Does this statement hold true?', '# Would you validate this statement?', '# Do you think this checks out?', '# Are you saying this is correct?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']),\n",
       " ContextQASample(context=\"The city of Rui'an is in Indonesia.\", questions=['# Would you say this is accurate?', '# Are these facts correct?', '# Am I right to believe this?', '# Would you say this is accurate?', '# Do you think this checks out?', '# Can you verify if this is true?', '# Does this information ring true?', '# Do you find this to be truthful?', '# Do you agree that this is true?', '# Can we confirm this is accurate?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Lilongwe is in Turkey.', questions=['# Does this statement hold true?', '# Is this true?', '# Would you say this is accurate?', '# Has this been verified as true?', '# Would you validate this statement?', '# Do you find this to be truthful?', '# Does this statement hold true?', '# Can you confirm the accuracy of this?', '# Are you confirming this is true?', '# May I assume this is correct?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Frankfurt am Main is in Vietnam.', questions=['# Could you tell me if this is factual?', '# Can you verify if this is true?', '# Do you agree that this is true?', '# Are you confirming this is true?', '# Are you saying this is correct?', '# Do you think this checks out?', '# Should I believe this statement?', '# Do you think this checks out?', '# Has this been verified as true?', '# Could you tell me if this is factual?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Voronezh is in Romania.', questions=['# Does this statement hold true?', '# Are you confirming this is true?', '# Would you say this is accurate?', '# May I assume this is correct?', '# Is this true?', '# Am I right to believe this?', '# Has this been verified as true?', '# Does this statement hold true?', '# Does this statement hold true?', '# Has this been verified as true?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Uberlandia is in India.', questions=['# Are you saying this is correct?', '# Am I right to believe this?', '# Do the facts support this statement?', '# Am I right to believe this?', '# Should I believe this statement?', '# Has this been verified as true?', '# Have I understood this correctly?', '# Do you think this checks out?', '# Does this information ring true?', '# Do you agree that this is true?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']),\n",
       " ContextQASample(context='The city of Guwahati is in China.', questions=['# Is this statement true?', '# Do you think this checks out?', '# Can you verify if this is true?', '# Do you agree that this is true?', '# Is this statement true?', '# Do you find this to be truthful?', '# Are you confirming this is true?', '# Can you confirm the accuracy of this?', '# Are you saying this is correct?', '# Does this information ring true?'], answers=['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "from src.utils.typing import LatentCache, LatentCacheCollection\n",
    "from src.tokens import prepare_input\n",
    "from src.functional import get_module_nnsight, interpret_logits\n",
    "from src.functional import get_batch_concept_activations\n",
    "\n",
    "# prompts = [\n",
    "#     \"Eiffel Tower is in which city? It is in\",\n",
    "#     \"A quick brown fox\",\n",
    "#     \"The sun rises in the\",\n",
    "# ]\n",
    "\n",
    "prompts = [\n",
    "    \"The land of the rising sun is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The Space Needle is a tower in\"\n",
    "]\n",
    "\n",
    "latents = get_batch_concept_activations(\n",
    "    mt=mt,\n",
    "    prompts=prompts,\n",
    "    interested_layer_indices=list(range(5, 20)),\n",
    "    check_prediction=None,\n",
    "    on_token_occur=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcc = LatentCacheCollection(latents=latents)\n",
    "lcc.detensorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-28 23:57:21 numexpr.utils INFO     Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-10-28 23:57:21 numexpr.utils INFO     NumExpr defaulting to 8 threads.\n",
      "2024-10-28 23:57:21 datasets INFO     PyTorch version 2.5.0 available.\n",
      "2024-10-28 23:57:21 src.dataset_manager INFO     Loaded 60 examples from commonsense/fruit_outside_color.\n"
     ]
    }
   ],
   "source": [
    "from src.dataset_manager import DatasetManager\n",
    "\n",
    "# group, name = \"relations\", \"factual/country_capital_city\"\n",
    "group, name = \"relations\", \"commonsense/fruit_outside_color\"\n",
    "\n",
    "dataloader = DatasetManager.from_named_datasets(\n",
    "    [\n",
    "        (group, name),\n",
    "    ],\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ContextQASample' object has no attribute 'correct'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m      5\u001b[0m prompts \u001b[38;5;241m=\u001b[39m [b\u001b[38;5;241m.\u001b[39mcontext \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch]    \n\u001b[1;32m      6\u001b[0m latents \u001b[38;5;241m=\u001b[39m get_batch_concept_activations(\n\u001b[1;32m      7\u001b[0m     mt\u001b[38;5;241m=\u001b[39mmt,\n\u001b[1;32m      8\u001b[0m     prompts\u001b[38;5;241m=\u001b[39mprompts,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     on_token_occur\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m correct_labels \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrect\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m incorrect_labels \u001b[38;5;241m=\u001b[39m [b\u001b[38;5;241m.\u001b[39mincorrect \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m latent_cache, correct, incorrect \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(latents, correct_labels, incorrect_labels):\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m prompts \u001b[38;5;241m=\u001b[39m [b\u001b[38;5;241m.\u001b[39mcontext \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch]    \n\u001b[1;32m      6\u001b[0m latents \u001b[38;5;241m=\u001b[39m get_batch_concept_activations(\n\u001b[1;32m      7\u001b[0m     mt\u001b[38;5;241m=\u001b[39mmt,\n\u001b[1;32m      8\u001b[0m     prompts\u001b[38;5;241m=\u001b[39mprompts,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     on_token_occur\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m correct_labels \u001b[38;5;241m=\u001b[39m [\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrect\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     15\u001b[0m incorrect_labels \u001b[38;5;241m=\u001b[39m [b\u001b[38;5;241m.\u001b[39mincorrect \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m latent_cache, correct, incorrect \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(latents, correct_labels, incorrect_labels):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ContextQASample' object has no attribute 'correct'"
     ]
    }
   ],
   "source": [
    "cache_dir = os.path.join(group, name)\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "for batch_idx, batch in tqdm(enumerate(dataloader)):\n",
    "    prompts = [b.context for b in batch]    \n",
    "    latents = get_batch_concept_activations(\n",
    "        mt=mt,\n",
    "        prompts=prompts,\n",
    "        interested_layer_indices=list(range(5, 20)),\n",
    "        check_prediction=None,\n",
    "        on_token_occur=None,\n",
    "    )\n",
    "\n",
    "    correct_labels = [b.correct for b in batch]\n",
    "    incorrect_labels = [b.incorrect for b in batch]\n",
    "\n",
    "    for latent_cache, correct, incorrect in zip(latents, correct_labels, incorrect_labels):\n",
    "        latent_cache.correct_label = correct\n",
    "        latent_cache.incorrect_label = incorrect\n",
    "        latent_cache.group=\"relations\"\n",
    "    \n",
    "    lcc = LatentCacheCollection(latents=latents)\n",
    "    lcc.detensorize()\n",
    "\n",
    "    with open(os.path.join(cache_dir, f\"batch_{batch_idx}.json\"), \"w\") as f:\n",
    "        f.write(lcc.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.activation_manager import ActivationLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_6.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_41.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_42.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_34.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_12.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_17.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_28.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_26.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_44.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_0.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_11.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_32.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_19.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_21.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_1.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_25.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_27.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_39.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_30.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_24.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_15.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_37.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_33.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_36.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_13.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_40.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_31.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_29.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_8.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_10.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_9.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_5.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_43.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_38.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_16.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_45.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_2.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_23.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_35.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_18.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_14.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_20.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_22.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_46.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_4.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_7.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/cities/batch_3.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_6.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_41.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_42.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_34.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_12.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_17.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_28.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_26.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_44.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_0.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_11.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_32.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_19.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_21.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_1.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_25.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_27.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_39.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_30.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_24.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_15.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_37.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_33.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_36.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_13.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_40.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_31.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_29.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_8.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_10.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_9.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_5.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_43.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_38.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_16.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_45.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_2.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_23.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_35.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_18.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_14.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_20.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_22.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_46.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_4.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_7.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/neg_cities/batch_3.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_6.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_50.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_41.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_42.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_34.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_12.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_17.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_28.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_26.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_44.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_53.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_0.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_11.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_32.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_59.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_19.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_21.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_1.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_25.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_27.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_39.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_30.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_24.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_15.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_48.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_37.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_60.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_33.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_36.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_13.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_40.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_31.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_29.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_49.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_8.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_10.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_58.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_9.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_5.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_43.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_38.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_16.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_45.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_55.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_2.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_23.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_56.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_61.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_35.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_47.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_18.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_57.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_54.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_52.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_14.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_20.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_22.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_46.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_4.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_7.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_51.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/smaller_than/batch_3.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/larger_than/batch_6.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/larger_than/batch_0.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/larger_than/batch_11.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/larger_than/batch_1.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/larger_than/batch_8.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/larger_than/batch_10.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/larger_than/batch_9.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/larger_than/batch_5.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/larger_than/batch_2.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/larger_than/batch_4.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/larger_than/batch_7.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/larger_than/batch_3.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/sp_en_trans/batch_6.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/sp_en_trans/batch_0.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/sp_en_trans/batch_11.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/sp_en_trans/batch_1.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/sp_en_trans/batch_8.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/sp_en_trans/batch_10.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/sp_en_trans/batch_9.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/sp_en_trans/batch_5.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/sp_en_trans/batch_2.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/sp_en_trans/batch_4.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/sp_en_trans/batch_7.json',\n",
       " '/home/local_arnab/Codes/Projects/talkative_probes/results/cached_latents/Llama-3.2-3B/geometry_of_truth/sp_en_trans/batch_3.json']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.activation_manager import ActivationLoader, get_batch_paths\n",
    "\n",
    "latent_root = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR, \n",
    "    \"cached_latents\", MODEL_KEY.split(\"/\")[-1], \"geometry_of_truth\"\n",
    ")\n",
    "\n",
    "activation_batch_paths = list(get_batch_paths(latent_root))\n",
    "activation_batch_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_loader = ActivationLoader(\n",
    "    latent_cache_files=activation_batch_paths,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_batch = act_loader.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ActivationSample(activation=tensor([ 0.0320,  0.0164,  0.0691,  ..., -0.0952,  0.4255, -0.1327]), context='Fifty-six is smaller than seventy-six.', question='# Are these facts correct?', label=' Yes', layer_name='model.layers.15'),\n",
       " ActivationSample(activation=tensor([ 0.0300,  0.2755,  0.0297,  ...,  0.0331,  0.3606, -0.1069]), context='Fifty-six is smaller than seventy-six.', question='# May I assume this is correct?', label=' Yes', layer_name='model.layers.16'),\n",
       " ActivationSample(activation=tensor([ 0.1466, -0.1212,  0.1019,  ...,  0.0743,  0.1145, -0.0166]), context='Seventy-eight is smaller than eighty-nine.', question='# Can you confirm the accuracy of this?', label=' Yes', layer_name='model.layers.11'),\n",
       " ActivationSample(activation=tensor([ 0.0613,  0.1951,  0.0546,  ..., -0.0468,  0.4112, -0.1386]), context='Seventy-nine is smaller than fifty-one.', question='# May I assume this is correct?', label=' No', layer_name='model.layers.16'),\n",
       " ActivationSample(activation=tensor([ 0.0573,  0.0847,  0.0788,  ..., -0.0318,  0.0450, -0.0450]), context='Eighty-nine is smaller than fifty-eight.', question='# Are you confirming this is true?', label=' No', layer_name='model.layers.10'),\n",
       " ActivationSample(activation=tensor([ 0.0167, -0.0255, -0.0382,  ..., -0.2055,  0.4112, -0.0940]), context='Eighty-nine is smaller than fifty-eight.', question='# Can you confirm the accuracy of this?', label=' No', layer_name='model.layers.15'),\n",
       " ActivationSample(activation=tensor([ 0.1260, -0.0197,  0.1962,  ...,  0.0873, -0.1005,  0.0093]), context='Seventy-nine is smaller than eighty-four.', question='# Would you say this is accurate?', label=' Yes', layer_name='model.layers.7'),\n",
       " ActivationSample(activation=tensor([ 0.1023,  0.0025, -0.0204,  ..., -0.0383,  0.3191,  0.1417]), context='Eighty-nine is smaller than fifty-eight.', question='# Are you saying this is correct?', label=' No', layer_name='model.layers.14'),\n",
       " ActivationSample(activation=tensor([ 0.0289,  0.1237,  0.1129,  ..., -0.0641,  0.0490, -0.0110]), context='Eighty-one is smaller than sixty-five.', question='# Do you think this checks out?', label=' No', layer_name='model.layers.10'),\n",
       " ActivationSample(activation=tensor([ 0.1403,  0.0070,  0.0568,  ..., -0.0199, -0.0389,  0.0372]), context='Eighty-nine is smaller than fifty-eight.', question='# Can you verify if this is true?', label=' No', layer_name='model.layers.9'),\n",
       " ActivationSample(activation=tensor([-0.0362,  0.0253,  0.0369,  ..., -0.0759,  0.4827, -0.1195]), context='Fifty-five is smaller than eighty-seven.', question='# Can you confirm the accuracy of this?', label=' Yes', layer_name='model.layers.15'),\n",
       " ActivationSample(activation=tensor([ 0.1945,  0.0643,  0.1758,  ...,  0.1080, -0.1187,  0.0279]), context='Ninety-one is smaller than fifty-one.', question='# Do you find this to be truthful?', label=' No', layer_name='model.layers.7'),\n",
       " ActivationSample(activation=tensor([ 0.0623,  0.0986,  0.0049,  ..., -0.0648,  0.3255,  0.0963]), context='Ninety-eight is smaller than fifty-four.', question='# Do you find this to be truthful?', label=' No', layer_name='model.layers.14'),\n",
       " ActivationSample(activation=tensor([ 0.1176, -0.0452, -0.0093,  ..., -0.0623,  0.2138,  0.0362]), context='Sixty-two is smaller than seventy-six.', question='# May I assume this is correct?', label=' Yes', layer_name='model.layers.12'),\n",
       " ActivationSample(activation=tensor([ 0.2210, -0.0390,  0.0767,  ..., -0.1278, -0.0709, -0.1262]), context='Seventy-five is smaller than fifty-two.', question='# Would you validate this statement?', label=' No', layer_name='model.layers.8'),\n",
       " ActivationSample(activation=tensor([ 0.0442,  0.0715,  0.0577,  ..., -0.0147, -0.0090,  0.0184]), context='Ninety-five is smaller than ninety-three.', question='# Are you saying this is correct?', label=' No', layer_name='model.layers.13'),\n",
       " ActivationSample(activation=tensor([ 0.1170, -0.0479,  0.0053,  ..., -0.0759,  0.1263,  0.0577]), context='Ninety-one is smaller than fifty-one.', question='# Can we confirm this is accurate?', label=' No', layer_name='model.layers.12'),\n",
       " ActivationSample(activation=tensor([ 0.0969,  0.0456,  0.2084,  ...,  0.1139, -0.1115,  0.0644]), context='Ninety-five is smaller than ninety-three.', question='# Are these facts correct?', label=' No', layer_name='model.layers.7'),\n",
       " ActivationSample(activation=tensor([ 0.0305,  0.1095, -0.0659,  ..., -0.2013,  0.3860, -0.0666]), context='Seventy-four is smaller than seventy-six.', question='# Are you saying this is correct?', label=' Yes', layer_name='model.layers.15'),\n",
       " ActivationSample(activation=tensor([-0.0346,  0.4671,  0.2040,  ..., -0.0918,  0.3922, -0.1314]), context='Fifty-six is smaller than eighty-two.', question='# May I assume this is correct?', label=' Yes', layer_name='model.layers.17'),\n",
       " ActivationSample(activation=tensor([ 0.0554,  0.0984,  0.1233,  ..., -0.0317,  0.0713,  0.0055]), context='Sixty-four is smaller than eighty-five.', question='# Would you consider this to be true?', label=' Yes', layer_name='model.layers.10'),\n",
       " ActivationSample(activation=tensor([ 0.0598,  0.0914,  0.0258,  ..., -0.0341,  0.3150,  0.0822]), context='Ninety-five is smaller than sixty-three.', question='# Do you find this to be truthful?', label=' No', layer_name='model.layers.14'),\n",
       " ActivationSample(activation=tensor([ 0.1298,  0.0794,  0.1635,  ...,  0.0618, -0.0777, -0.0042]), context='Sixty-four is smaller than eighty-five.', question='# Are you confirming this is true?', label=' Yes', layer_name='model.layers.7'),\n",
       " ActivationSample(activation=tensor([ 0.1312, -0.0351,  0.1320,  ..., -0.0956, -0.0421, -0.1089]), context='Ninety-five is smaller than ninety-three.', question='# Are these facts correct?', label=' No', layer_name='model.layers.8'),\n",
       " ActivationSample(activation=tensor([ 0.1475, -0.0687,  0.1090,  ..., -0.0291, -0.0263,  0.0270]), context='Eighty-two is smaller than eighty-three.', question='# Does this information ring true?', label=' Yes', layer_name='model.layers.9'),\n",
       " ActivationSample(activation=tensor([ 0.0958,  0.1543,  0.0029,  ..., -0.0365,  0.3569,  0.0399]), context='Sixty-two is smaller than seventy-six.', question='# Are you saying this is correct?', label=' Yes', layer_name='model.layers.14'),\n",
       " ActivationSample(activation=tensor([ 0.0449,  0.0587,  0.0324,  ..., -0.2030,  0.3833, -0.0926]), context='Seventy-five is smaller than fifty-two.', question='# Have I understood this correctly?', label=' No', layer_name='model.layers.15'),\n",
       " ActivationSample(activation=tensor([ 0.1549, -0.0545,  0.1192,  ..., -0.1135, -0.0732, -0.1373]), context='Seventy-nine is smaller than fifty-one.', question='# Is this true?', label=' No', layer_name='model.layers.8'),\n",
       " ActivationSample(activation=tensor([ 0.1030, -0.0920, -0.0203,  ..., -0.0304,  0.0550,  0.0003]), context='Seventy-eight is smaller than seventy-seven.', question='# Would you validate this statement?', label=' No', layer_name='model.layers.12'),\n",
       " ActivationSample(activation=tensor([ 0.0929, -0.0588, -0.0166,  ..., -0.0699,  0.1218,  0.0507]), context='Ninety-six is smaller than eighty-three.', question='# Does this information ring true?', label=' No', layer_name='model.layers.12'),\n",
       " ActivationSample(activation=tensor([ 0.0886,  0.2266, -0.0244,  ..., -0.0791,  0.3793, -0.1113]), context='Fifty-three is smaller than fifty-one.', question='# Are these facts correct?', label=' No', layer_name='model.layers.16'),\n",
       " ActivationSample(activation=tensor([ 0.1181,  0.0537,  0.1590,  ...,  0.0598, -0.1101, -0.0098]), context='Fifty-nine is smaller than sixty-three.', question='# Would you say this is accurate?', label=' Yes', layer_name='model.layers.7')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"# Does this passage concern a male person?\",\n",
    "    \"# Does this text explore Business?\",\n",
    "    \"# Is the subject of this sentence female?\",\n",
    "    \"# Does this review indicate a poor experience?\",\n",
    "    \"# Is this talking about a female person?\",\n",
    "    \"# Does the reviewer appear displeased with their experience?\",\n",
    "    \"# Does this refer to a male individual?\",\n",
    "    \"# Is the overall message of this review negative?\",\n",
    "    \"# Can this article be categorized under World News?\",\n",
    "    \"# Can this article be categorized under Business?\",\n",
    "    \"# In terms of content, does this piece deal with World News?\",\n",
    "    \"# Is Central African Republic mentioned anywhere in the passage?\",\n",
    "    \"# Could you tell me if this is factual?\",\n",
    "    \"# Is Rally of in any part of this passage?\",\n",
    "    \"# Is Israeli cited in this piece?\",\n",
    "    \"# Is there a positive tone throughout this review?\",\n",
    "    \"# Does this describe someone who is female?\",\n",
    "    \"# Does this text explore Sports?\",\n",
    "    \"# Is Japanese referenced in this text?\",\n",
    "    \"# Could this be summarized as an article about Business?\",\n",
    "    \"# Can you find any references to since November in this text?\",\n",
    "    \"# Would you classify this as an endorsement?\",\n",
    "    \"# Are you confirming this is true?\",\n",
    "    \"# Is 1498 discussed anywhere in this content?\",\n",
    "    \"# Does this text refer to March?\",\n",
    "    \"# Is there a substantial focus on Business in this article?\",\n",
    "    \"# Is the general sentiment of this review negative?\",\n",
    "    # \"# Does Rwanda \\x92s appear in this text?\",\n",
    "    \"# Is the sentiment in this review on the negative side?\",\n",
    "    \"# Does this article delve into matters concerning Science/Technology?\",\n",
    "    \"# Is there a substantial focus on World News in this article?\",\n",
    "    \"# Is this sentence about a female person?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-30 12:35:23 numexpr.utils INFO     Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-10-30 12:35:23 numexpr.utils INFO     NumExpr defaulting to 8 threads.\n",
      "2024-10-30 12:35:23 datasets INFO     PyTorch version 2.5.0 available.\n",
      "2024-10-30 12:35:23 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-30 12:35:23 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/FrancophonIA/WiLI-2018 HTTP/11\" 200 1480\n",
      "2024-10-30 12:35:23 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2024-10-30 12:35:23 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/FrancophonIA/WiLI-2018/FrancophonIA/WiLI-2018.py HTTP/11\" 404 0\n",
      "2024-10-30 12:35:23 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/FrancophonIA/WiLI-2018 HTTP/11\" 200 1480\n",
      "2024-10-30 12:35:23 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-30 12:35:24 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/FrancophonIA/WiLI-2018/resolve/d505038b20006eb17994578c1e870d443f1cd5d2/README.md HTTP/11\" 200 0\n",
      "2024-10-30 12:35:24 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-30 12:35:24 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/FrancophonIA/WiLI-2018/resolve/d505038b20006eb17994578c1e870d443f1cd5d2/.huggingface.yaml HTTP/11\" 404 0\n",
      "2024-10-30 12:35:24 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2024-10-30 12:35:24 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=FrancophonIA/WiLI-2018 HTTP/11\" 200 None\n",
      "2024-10-30 12:35:24 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/FrancophonIA/WiLI-2018/revision/d505038b20006eb17994578c1e870d443f1cd5d2 HTTP/11\" 200 1480\n",
      "2024-10-30 12:35:24 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/FrancophonIA/WiLI-2018/tree/d505038b20006eb17994578c1e870d443f1cd5d2?recursive=False&expand=False HTTP/11\" 200 412\n",
      "2024-10-30 12:35:24 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/FrancophonIA/WiLI-2018/tree/d505038b20006eb17994578c1e870d443f1cd5d2/data?recursive=False&expand=False HTTP/11\" 404 79\n",
      "2024-10-30 12:35:24 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-30 12:35:24 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/FrancophonIA/WiLI-2018/revision/d505038b20006eb17994578c1e870d443f1cd5d2 HTTP/11\" 200 1480\n",
      "2024-10-30 12:35:24 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-30 12:35:24 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/FrancophonIA/WiLI-2018/resolve/d505038b20006eb17994578c1e870d443f1cd5d2/dataset_infos.json HTTP/11\" 404 0\n",
      "2024-10-30 12:35:24 filelock DEBUG    Attempting to acquire lock 140562955438480 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_FrancophonIA___wi_li-2018_default_0.0.0_d505038b20006eb17994578c1e870d443f1cd5d2.lock\n",
      "2024-10-30 12:35:24 filelock DEBUG    Lock 140562955438480 acquired on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_FrancophonIA___wi_li-2018_default_0.0.0_d505038b20006eb17994578c1e870d443f1cd5d2.lock\n",
      "2024-10-30 12:35:24 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/FrancophonIA___wi_li-2018/default/0.0.0/d505038b20006eb17994578c1e870d443f1cd5d2/dataset_info.json\n",
      "2024-10-30 12:35:24 filelock DEBUG    Attempting to release lock 140562955438480 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_FrancophonIA___wi_li-2018_default_0.0.0_d505038b20006eb17994578c1e870d443f1cd5d2.lock\n",
      "2024-10-30 12:35:24 filelock DEBUG    Lock 140562955438480 released on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_FrancophonIA___wi_li-2018_default_0.0.0_d505038b20006eb17994578c1e870d443f1cd5d2.lock\n",
      "2024-10-30 12:35:24 filelock DEBUG    Attempting to acquire lock 140562949983248 on /home/local_arnab/.cache/huggingface/datasets/FrancophonIA___wi_li-2018/default/0.0.0/d505038b20006eb17994578c1e870d443f1cd5d2_builder.lock\n",
      "2024-10-30 12:35:24 filelock DEBUG    Lock 140562949983248 acquired on /home/local_arnab/.cache/huggingface/datasets/FrancophonIA___wi_li-2018/default/0.0.0/d505038b20006eb17994578c1e870d443f1cd5d2_builder.lock\n",
      "2024-10-30 12:35:24 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/FrancophonIA___wi_li-2018/default/0.0.0/d505038b20006eb17994578c1e870d443f1cd5d2/dataset_info.json\n",
      "2024-10-30 12:35:24 filelock DEBUG    Attempting to release lock 140562949983248 on /home/local_arnab/.cache/huggingface/datasets/FrancophonIA___wi_li-2018/default/0.0.0/d505038b20006eb17994578c1e870d443f1cd5d2_builder.lock\n",
      "2024-10-30 12:35:24 filelock DEBUG    Lock 140562949983248 released on /home/local_arnab/.cache/huggingface/datasets/FrancophonIA___wi_li-2018/default/0.0.0/d505038b20006eb17994578c1e870d443f1cd5d2_builder.lock\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ContextQASample(context='perhitungan dasar yang berlaku sejak zaman pertengahan adalah paskah dirayakan pada hari minggu setelah bulan purnama pertama setelah hari pertama musim semi vernal equinox kalimat tersebut sebenarnya tidak tepat benar dengan sistem perhitungan gerejawi', questions=['# Is this text predominantly in Korean?', '# Is this text predominantly in Indonesian?', '# Is this passage composed in Chinese?', '# Is this passage composed in Swedish?', '# Is this written in the language Romanian?', '# Would you classify this as written in Indonesian?', '# Is this text written in Indonesian?', '# Can we confirm this is in Urdu?', '# Is the text presented in Indonesian?', '# Is this text predominantly in Russian?'], answers=['No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No']),\n",
       " ContextQASample(context='denna typ av kommersiell och välproducerad rock fortsatte på deras nästa skiva outside inside som kom  på denna skiva kom deras första top -hit på billboardlistan \"shes a beauty\" en låt där för övrigt totos dåvarande gitarrist steve lukather medverkade  kom love bomb producerad av todd rundgren som de tidigare arbetat med på remote control skivan blev en total flopp och gruppen splittrades kort därefter', questions=['# Am I correct in saying this is in Swedish?', '# Is this text written in Swedish?', '# Is the content of this text in Swedish?', '# Is this text predominantly in Swedish?', '# Is the text presented in Chinese?', '# Is this passage composed in Latin?', '# Is this written in the language Portugese?', '# Can we confirm this is in Swedish?', '# Does this writing reflect the language Turkish?', '# Can we determine that this is in Swedish?'], answers=['Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes']),\n",
       " ContextQASample(context='لا يعتمد اختيار أي نظام اتصال من بعد لتحقيق أغراض معينة على التقنية الممكن استخدامها وكلفتها فقط بل على الكلفة النسبية للحلول المختلفة المتوافرة ويلجأ للموازنة بين مختلف الحلول والمنظومات المحتملة اقتصادياً إلى دراسة القيمة الحالية للكلفة السنوية present value of annoal chargespvac التي تراعي كلاً من رأس المال والنفقات المستمرة للمشروع في المدة الزمنية الكلية المتوقعة لاستثماره والتي لا تقل عن عشرين سنة أما من وجهة نظر مميزات التمويل النقدي لمختلف النفقات فإن أفضل المشاريع هي التي يمكن تجزئتها إلى مراحل لتفي كل مرحلة منها بالمتطلبات الحالية والمتوقعة لمدة زمنية قصيرة', questions=['# Am I correct in saying this is in Turkish?', '# Is this written in the language Arabic?', '# Can we confirm this is in Arabic?', '# Is the language of this text Arabic?', '# Is the content of this text in Estonian?', '# Can we determine that this is in Arabic?', '# Is the language used here Russian?', '# Is this passage composed in Arabic?', '# Is the language used here Spanish?', '# Can we confirm this is in Arabic?'], answers=['No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes']),\n",
       " ContextQASample(context='comodo securebox - temmuz  yılında piyasaya sürülen ve ortaklaşa halihazırda tehlikelerin bu tür finansal işlemler gibi hassas faaliyetleri yürütmek için gereken bir uygulama olarak problem çözme niyetiyle western union ile geliştirilmiştir securebox çevreleme teknolojisi uygulamasının etkinlikleri bilgisayara kötücül yazılım bulaşmış olsa bile korur', questions=['# Can we say this is in Turkish?', '# Is the content of this text in Chinese?', '# Is the language of this text Turkish?', '# Would you agree that this is in Tamil?', '# Can we determine that this is in Turkish?', '# Does this passage use Russian?', '# Is this text written in Turkish?', '# Can we determine that this is in Turkish?', '# Is this text predominantly in Turkish?', '# Is this passage composed in Tamil?'], answers=['Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No']),\n",
       " ContextQASample(context='आइनस्टाइन ने कहा कि आपेक्षिकता के सिद्धान्त के अनुसार यह विचार कि भौतिक वस्तुएँ एक दूसर को आकर्षित करती हैं एक भ्रम है जो प्रकृति संबंधी गलत याँत्रिक धारणाओं के कारण पैदा हुआ है। उन्होंने कहा कि पृथ्वी बड़ी है और उसकी वजह से उसके इर्द-गिर्द का दिक्-काल मुड़ गया है और अपने ऊपर तह हो गया है। हम इस खिचे-मुड़े दिक्-काल में रहते हैं और इस मुड़न की वजह से पृथ्वी के क़रीब धकेले जाते हैं। इसकी तुलना एक चादर से की जा सकती है जिसके चार कोनो को चार लोगों ने खींच के पकड़ा हो। अब इस चादर के बीच में एक भारी गोला रख दिया जाए तो चादर बीच से बैठ जाएगी यानि उसके सूत में बीच में मुड़न पैदा हो जाएगी। अब अगर एक हलकी गेंद हम चादर के कोने पर रखे तो वह लुड़क कर बड़े गोले की तरफ़ जाएगी। आइनस्टाइन ने कहा कि कोई अनाड़ी आदमी यह देख कर कह सकता है कि छोटी गेंद को बड़े गोले ने खींचा इसलिए गेंद उसके पास गई। लेकिन असली वजह थी कि गेंद ज़मीन की तरफ़ जाना चाहती थी और गोले ने चादर में कुछ ऐसी मुड़न पैदा की कि गेंद उसके पास चली गई। इसी तरह से उन्होंने कहा कि यह एक मिथ्या है कि गुरुत्वाकर्षण किसी आकर्षण की वजह से होता है। गुरुत्वाकर्षण की असली वजह है कि हर वस्तु जो अंतरिक्ष में चल रही होती है वह दिक् के ऐसी मुड़न के प्रभाव में आकर किसी बड़ी चीज़ की ओर चलने लगती है।', questions=['# Can we say this is in Hindi?', '# Does this passage use Pushto?', '# Is the content of this text in Russian?', '# Is this written in the language Estonian?', '# Is this written in the language Chinese?', '# Is this text predominantly in Hindi?', '# Is the language used here Hindi?', '# Can we say this is in Spanish?', '# Am I correct in saying this is in Hindi?', '# Would you identify this text as being in Hindi?'], answers=['Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes'])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataset_manager import DatasetManager\n",
    "dataloader = DatasetManager.from_named_datasets(\n",
    "    # [(\"geometry_of_truth\", \"cities\")],\n",
    "    # [(\"sst2\", \"sst2\")],\n",
    "    # [(\"relations\", 'factual/country_capital_city')],\n",
    "    # [(\"tense\", \"tense\")],\n",
    "    [(\"language_identification\", \"language_identification\")],\n",
    "    batch_size=5\n",
    ")\n",
    "batch = next(iter(dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perhitungan dasar yang berlaku sejak zaman pertengahan adalah paskah dirayakan pada hari minggu setelah bulan purnama pertama setelah hari pertama musim semi vernal equinox kalimat tersebut sebenarnya tidak tepat benar dengan sistem perhitungan gerejawi',\n",
       " 'denna typ av kommersiell och välproducerad rock fortsatte på deras nästa skiva outside inside som kom  på denna skiva kom deras första top -hit på billboardlistan \"shes a beauty\" en låt där för övrigt totos dåvarande gitarrist steve lukather medverkade  kom love bomb producerad av todd rundgren som de tidigare arbetat med på remote control skivan blev en total flopp och gruppen splittrades kort därefter',\n",
       " 'لا يعتمد اختيار أي نظام اتصال من بعد لتحقيق أغراض معينة على التقنية الممكن استخدامها وكلفتها فقط بل على الكلفة النسبية للحلول المختلفة المتوافرة ويلجأ للموازنة بين مختلف الحلول والمنظومات المحتملة اقتصادياً إلى دراسة القيمة الحالية للكلفة السنوية present value of annoal chargespvac التي تراعي كلاً من رأس المال والنفقات المستمرة للمشروع في المدة الزمنية الكلية المتوقعة لاستثماره والتي لا تقل عن عشرين سنة أما من وجهة نظر مميزات التمويل النقدي لمختلف النفقات فإن أفضل المشاريع هي التي يمكن تجزئتها إلى مراحل لتفي كل مرحلة منها بالمتطلبات الحالية والمتوقعة لمدة زمنية قصيرة',\n",
       " 'comodo securebox - temmuz  yılında piyasaya sürülen ve ortaklaşa halihazırda tehlikelerin bu tür finansal işlemler gibi hassas faaliyetleri yürütmek için gereken bir uygulama olarak problem çözme niyetiyle western union ile geliştirilmiştir securebox çevreleme teknolojisi uygulamasının etkinlikleri bilgisayara kötücül yazılım bulaşmış olsa bile korur',\n",
       " 'आइनस्टाइन ने कहा कि आपेक्षिकता के सिद्धान्त के अनुसार यह विचार कि भौतिक वस्तुएँ एक दूसर को आकर्षित करती हैं एक भ्रम है जो प्रकृति संबंधी गलत याँत्रिक धारणाओं के कारण पैदा हुआ है। उन्होंने कहा कि पृथ्वी बड़ी है और उसकी वजह से उसके इर्द-गिर्द का दिक्-काल मुड़ गया है और अपने ऊपर तह हो गया है। हम इस खिचे-मुड़े दिक्-काल में रहते हैं और इस मुड़न की वजह से पृथ्वी के क़रीब धकेले जाते हैं। इसकी तुलना एक चादर से की जा सकती है जिसके चार कोनो को चार लोगों ने खींच के पकड़ा हो। अब इस चादर के बीच में एक भारी गोला रख दिया जाए तो चादर बीच से बैठ जाएगी यानि उसके सूत में बीच में मुड़न पैदा हो जाएगी। अब अगर एक हलकी गेंद हम चादर के कोने पर रखे तो वह लुड़क कर बड़े गोले की तरफ़ जाएगी। आइनस्टाइन ने कहा कि कोई अनाड़ी आदमी यह देख कर कह सकता है कि छोटी गेंद को बड़े गोले ने खींचा इसलिए गेंद उसके पास गई। लेकिन असली वजह थी कि गेंद ज़मीन की तरफ़ जाना चाहती थी और गोले ने चादर में कुछ ऐसी मुड़न पैदा की कि गेंद उसके पास चली गई। इसी तरह से उन्होंने कहा कि यह एक मिथ्या है कि गुरुत्वाकर्षण किसी आकर्षण की वजह से होता है। गुरुत्वाकर्षण की असली वजह है कि हर वस्तु जो अंतरिक्ष में चल रही होती है वह दिक् के ऐसी मुड़न के प्रभाव में आकर किसी बड़ी चीज़ की ओर चलने लगती है।']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = [\n",
    "    b.context for b in batch\n",
    "]\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128001, 128001, 128001,  ...,  67387,     73,  41978],\n",
       "        [128001, 128001, 128001,  ...,    294,  47786,   1064],\n",
       "        [128001, 128001, 128001,  ...,  74541, 115315, 103352],\n",
       "        [128001, 128001, 128001,  ...,  73394,  33054,    324],\n",
       "        [128000, 102393, 116333,  ...,  44747,  85410, 100436]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'offset_mapping': tensor([[[   0,    0],\n",
       "         [   0,    0],\n",
       "         [   0,    0],\n",
       "         ...,\n",
       "         [ 244,  249],\n",
       "         [ 249,  250],\n",
       "         [ 250,  253]],\n",
       "\n",
       "        [[   0,    0],\n",
       "         [   0,    0],\n",
       "         [   0,    0],\n",
       "         ...,\n",
       "         [ 397,  399],\n",
       "         [ 399,  402],\n",
       "         [ 402,  406]],\n",
       "\n",
       "        [[   0,    0],\n",
       "         [   0,    0],\n",
       "         [   0,    0],\n",
       "         ...,\n",
       "         [ 565,  567],\n",
       "         [ 567,  570],\n",
       "         [ 570,  573]],\n",
       "\n",
       "        [[   0,    0],\n",
       "         [   0,    0],\n",
       "         [   0,    0],\n",
       "         ...,\n",
       "         [ 341,  346],\n",
       "         [ 346,  350],\n",
       "         [ 350,  352]],\n",
       "\n",
       "        [[   0,    0],\n",
       "         [   0,    1],\n",
       "         [   1,    3],\n",
       "         ...,\n",
       "         [1139, 1140],\n",
       "         [1140, 1142],\n",
       "         [1142, 1144]]], device='cuda:0')}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.tokens import prepare_input, find_token_range\n",
    "\n",
    "# prompts = [\n",
    "#     \"The land of\",\n",
    "#     \"The capital of France is\",\n",
    "#     \"This is a\"\n",
    "# ]\n",
    "\n",
    "batch_inputs = prepare_input(\n",
    "    tokenizer=mt,\n",
    "    prompts=prompts,\n",
    "    padding_side=\"left\",\n",
    "    # padding=\"max_length\",\n",
    "    # max_length=20,\n",
    "    truncation=True,\n",
    "    return_offsets_mapping=True\n",
    ")\n",
    "\n",
    "batch_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 589])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|end_of_text|><|begin_of_text|>The land of',\n",
       " '<|begin_of_text|>The capital of France',\n",
       " '<|end_of_text|><|begin_of_text|>This is a']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    mt.tokenizer.decode(inp, skip_special_tokens=False)\n",
    "    for inp in batch_inputs[\"input_ids\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Are you working with Llama-3? Try passing the ModelandTokenizer object as the tokenizer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfind_token_range\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubstring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moffset_mapping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Codes/Projects/talkative_probes/notebooks/../src/tokens.py:219\u001b[0m, in \u001b[0;36mfind_token_range\u001b[0;34m(string, substring, tokenizer, occurrence, offset_mapping, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# print(f\"{substring=}, {occurrence=} | {token_start=}, {token_end=}\")\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m--> 219\u001b[0m     token_start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    220\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAre you working with Llama-3? Try passing the ModelandTokenizer object as the tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m token_end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m token_start \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m token_end\n",
      "\u001b[0;31mAssertionError\u001b[0m: Are you working with Llama-3? Try passing the ModelandTokenizer object as the tokenizer"
     ]
    }
   ],
   "source": [
    "find_token_range(\n",
    "    string=prompts[1],\n",
    "    substring=\"is\",\n",
    "    tokenizer=mt,\n",
    "    offset_mapping=batch_inputs[\"offset_mapping\"][1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['geometry_of_truth',\n",
       " 'relations',\n",
       " 'sst2',\n",
       " 'md_gender',\n",
       " 'snli',\n",
       " 'ag_news',\n",
       " 'ner',\n",
       " 'tense',\n",
       " 'language_identification',\n",
       " 'singular_plural']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(DatasetManager.list_datasets_by_group().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
